{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install pandas transformers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch + cuda: 2.6.0+cu124\n",
            "Is cuda avialable: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"torch + cuda:\", torch.__version__) # Check PyTorch version\n",
        "print(\"Is cuda avialable:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET = \"FoCus\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(f'./datasets/{DATASET}/train.json') as f:\n",
        "    valid_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convertToDialogue(my_list):\n",
        "    formatted_string = \"\"\n",
        "    for index, item in enumerate(my_list):\n",
        "        if index % 2 == 0:\n",
        "            user = \"User1\"\n",
        "        else:\n",
        "            user = \"User2\"\n",
        "        formatted_string += f\"{user}: {item}\\n\"\n",
        "    formatted_string = formatted_string.rstrip(\"\\n\")\n",
        "    return formatted_string\n",
        "\n",
        "flattened_data = []\n",
        "data_list = valid_data['data']\n",
        "for entry in data_list:\n",
        "    persona =  \"\".join(entry['persona'])\n",
        "    list_length = len(entry[\"utterance\"])\n",
        "    last_utterance = entry[\"utterance\"][-1]\n",
        "    dialogue_key = f\"dialogue{list_length}\"\n",
        "    last_item = last_utterance[dialogue_key]\n",
        "    flattened_data.append({\n",
        "                'dialogID': entry['dialogID'],\n",
        "                'persona': persona,\n",
        "                'utterance': convertToDialogue(last_item)\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(flattened_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personas</th>\n",
              "      <th>context</th>\n",
              "      <th>act_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like to go to Church.I am Roman Catholic.I w...</td>\n",
              "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
              "      <td>User2: It is in Texas state.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I like living in a city.I dont hope to ever vi...</td>\n",
              "      <td>User1: I know this place, but I dont remember ...</td>\n",
              "      <td>User2: Of course, Captain William Cornwallis S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to visit Mexico.I am interested in the ...</td>\n",
              "      <td>User1: I know this place, but I dont remember ...</td>\n",
              "      <td>User2: Well, in this rainforest, especially th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am afraid of bears.I like valleys.I live in ...</td>\n",
              "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
              "      <td>User2: Not only it, but there are various othe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            personas  \\\n",
              "0  I like to go to Church.I am Roman Catholic.I w...   \n",
              "1  I like living in a city.I dont hope to ever vi...   \n",
              "2  I want to visit Mexico.I am interested in the ...   \n",
              "3  I am afraid of bears.I like valleys.I live in ...   \n",
              "\n",
              "                                             context  \\\n",
              "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
              "1  User1: I know this place, but I dont remember ...   \n",
              "2  User1: I know this place, but I dont remember ...   \n",
              "3  User1: Where is this place?\\nUser2: This place...   \n",
              "\n",
              "                                        act_response  \n",
              "0                       User2: It is in Texas state.  \n",
              "1  User2: Of course, Captain William Cornwallis S...  \n",
              "2  User2: Well, in this rainforest, especially th...  \n",
              "3  User2: Not only it, but there are various othe...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.replace(r'\\*\\*', '', regex=True)\n",
        "df = df.replace(r'\\r', '', regex=True)\n",
        "df = df.replace(\"'\", \"\", regex=True)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Function to split the conversation\n",
        "def split_conversation(conv_str):\n",
        "    utterances = conv_str.split(\"\\n\")\n",
        "    context = \"\\n\".join(utterances[:-1])\n",
        "    response = utterances[-1]\n",
        "    return context, response\n",
        "\n",
        "new_rows = []\n",
        "for index, row in df.iterrows():\n",
        "    context, response = split_conversation(row['utterance'])\n",
        "    new_row = {\n",
        "        'personas': row['persona'],\n",
        "        'context': context,\n",
        "        'act_response': response\n",
        "    }\n",
        "    new_rows.append(new_row)\n",
        "\n",
        "new_df = pd.DataFrame(new_rows)\n",
        "\n",
        "new_df.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persona Length (in words): 11-92\n",
            "Context Length (in words): 46-705\n",
            "Response Length (in words): 2-159\n"
          ]
        }
      ],
      "source": [
        "# Calculate minimum and maximum number of words in each column\n",
        "min_persona_length = new_df['personas'].apply(lambda x: len(x.split())).min()\n",
        "max_persona_length = new_df['personas'].apply(lambda x: len(x.split())).max()\n",
        "\n",
        "min_context_length = new_df['context'].apply(lambda x: len(x.split())).min()\n",
        "max_context_length = new_df['context'].apply(lambda x: len(x.split())).max()\n",
        "\n",
        "min_response_length = new_df['act_response'].apply(lambda x: len(x.split())).min()\n",
        "max_response_length = new_df['act_response'].apply(lambda x: len(x.split())).max()\n",
        "\n",
        "# Print the lengths in min-max format\n",
        "print(f\"Persona Length (in words): {min_persona_length}-{max_persona_length}\")\n",
        "print(f\"Context Length (in words): {min_context_length}-{max_context_length}\")\n",
        "print(f\"Response Length (in words): {min_response_length}-{max_response_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv(f'./datasets/{DATASET}/ds_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PAA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The model consists of the following key components:**\n",
        "\n",
        "- Persona Encoder - Applies self-attention to persona embeddings.\n",
        "- Context Encoder - Applies self-attention to dialogue history embeddings.\n",
        "- Persona-Adaptive Attention (PAA) - Uses cross-attention between persona and context, dynamically adjusting their influence.\n",
        "- Dialogue Decoder - Generates responses using a transformer-based model, incorporating persona-aware representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3TEn-DkQqaIa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/salehafzoon/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET = \"FoCus\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCS = 100\n",
        "EMBEDDING_SIZE = 768\n",
        "MAX_LENGTH_TOKEN = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xc6sA-zMrcWS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "\n",
        "csv_path = f\"datasets/{DATASET}/ds_cleaned.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "assert \"personas\" in df.columns and \"context\" in df.columns and \"act_response\" in df.columns, \"Missing columns in dataset!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personas</th>\n",
              "      <th>context</th>\n",
              "      <th>act_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like to go to Church.I am Roman Catholic.I w...</td>\n",
              "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
              "      <td>User2: It is in Texas state.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I like living in a city.I dont hope to ever vi...</td>\n",
              "      <td>User1: I know this place, but I dont remember ...</td>\n",
              "      <td>User2: Of course, Captain William Cornwallis S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to visit Mexico.I am interested in the ...</td>\n",
              "      <td>User1: I know this place, but I dont remember ...</td>\n",
              "      <td>User2: Well, in this rainforest, especially th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am afraid of bears.I like valleys.I live in ...</td>\n",
              "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
              "      <td>User2: Not only it, but there are various othe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would like to visit New Zealand.I would like...</td>\n",
              "      <td>User1: I think Ive been there before but I don...</td>\n",
              "      <td>User2: Prior to a 2006–2008 street upgrade, Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            personas  \\\n",
              "0  I like to go to Church.I am Roman Catholic.I w...   \n",
              "1  I like living in a city.I dont hope to ever vi...   \n",
              "2  I want to visit Mexico.I am interested in the ...   \n",
              "3  I am afraid of bears.I like valleys.I live in ...   \n",
              "4  I would like to visit New Zealand.I would like...   \n",
              "\n",
              "                                             context  \\\n",
              "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
              "1  User1: I know this place, but I dont remember ...   \n",
              "2  User1: I know this place, but I dont remember ...   \n",
              "3  User1: Where is this place?\\nUser2: This place...   \n",
              "4  User1: I think Ive been there before but I don...   \n",
              "\n",
              "                                        act_response  \n",
              "0                       User2: It is in Texas state.  \n",
              "1  User2: Of course, Captain William Cornwallis S...  \n",
              "2  User2: Well, in this rainforest, especially th...  \n",
              "3  User2: Not only it, but there are various othe...  \n",
              "4  User2: Prior to a 2006–2008 street upgrade, Co...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6ri_0imWq8qH"
      },
      "outputs": [],
      "source": [
        "# class SelfAttention(nn.Module):\n",
        "#     \"\"\"Single-head self-attention mechanism.\"\"\"\n",
        "#     def __init__(self, embed_size):\n",
        "#         super(SelfAttention, self).__init__()\n",
        "#         self.query = nn.Linear(embed_size, embed_size)\n",
        "#         self.key = nn.Linear(embed_size, embed_size)\n",
        "#         self.value = nn.Linear(embed_size, embed_size)\n",
        "#         self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         Q = self.query(x)\n",
        "#         K = self.key(x)\n",
        "#         V = self.value(x)\n",
        "\n",
        "#         attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (K.shape[-1] ** 0.5)\n",
        "#         attention_weights = self.softmax(attention_scores)\n",
        "\n",
        "#         output = torch.matmul(attention_weights, V)\n",
        "#         return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    \"\"\"Multi-head attention-based Transformer Encoder layer.\"\"\"\n",
        "    def __init__(self, embed_size, num_heads=4, ff_hidden_size=1024, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        \n",
        "        self.self_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "        \n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, ff_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_size, embed_size)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Self-attention layer\n",
        "        attn_output, _ = self.self_attention(x, x, x)\n",
        "        x = self.norm1(x + self.dropout(attn_output))  # Residual connection + LayerNorm\n",
        "        \n",
        "        # Feed-forward network\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))  # Residual connection + LayerNorm\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "htF3dXB5rAmK"
      },
      "outputs": [],
      "source": [
        "# class PersonaEncoder(nn.Module):\n",
        "#     def __init__(self, embed_size):\n",
        "#         super(PersonaEncoder, self).__init__()\n",
        "#         self.attention = SelfAttention(embed_size)\n",
        "#         self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "#     def forward(self, persona_embeds):\n",
        "#         attended = self.attention(persona_embeds)\n",
        "#         return self.norm(attended + persona_embeds)  # Residual Connection\n",
        "\n",
        "# class ContextEncoder(nn.Module):\n",
        "#     def __init__(self, embed_size):\n",
        "#         super(ContextEncoder, self).__init__()\n",
        "#         self.attention = SelfAttention(embed_size)\n",
        "#         self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "#     def forward(self, context_embeds):\n",
        "#         attended = self.attention(context_embeds)\n",
        "#         return self.norm(attended + context_embeds)  # Residual Connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CWkiehFkrDee"
      },
      "outputs": [],
      "source": [
        "class PersonaEncoder(nn.Module):\n",
        "    def __init__(self, embed_size, num_layers=4):\n",
        "        super(PersonaEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([TransformerEncoderLayer(embed_size) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, persona_embeds):\n",
        "        x = persona_embeds  # Shape: (seq_len, batch_size, embed_size)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x  # Encoded persona representation\n",
        "\n",
        "\n",
        "class ContextEncoder(nn.Module):\n",
        "    def __init__(self, embed_size, num_layers=4):\n",
        "        super(ContextEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([TransformerEncoderLayer(embed_size) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, context_embeds):\n",
        "        x = context_embeds  # Shape: (seq_len, batch_size, embed_size)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x  # Encoded context representation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iDytCbW-rG-O"
      },
      "outputs": [],
      "source": [
        "# class PersonaAdaptiveAttention(nn.Module):\n",
        "#     def __init__(self, embed_size):\n",
        "#         super(PersonaAdaptiveAttention, self).__init__()\n",
        "#         self.context_attention = SelfAttention(embed_size)\n",
        "#         self.persona_attention = SelfAttention(embed_size)\n",
        "\n",
        "#         self.weighting = nn.Linear(embed_size, 1)  # Adaptive weighting\n",
        "#         self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "#     def forward(self, persona_embeds, context_embeds):\n",
        "#         attended_context = self.context_attention(context_embeds)\n",
        "#         attended_persona = self.persona_attention(persona_embeds)\n",
        "\n",
        "#         # Adaptive Weighting (From PAA Mechanism)\n",
        "#         weights = torch.sigmoid(self.weighting(attended_persona))\n",
        "#         weighted_persona = weights * attended_persona\n",
        "\n",
        "#         # Fusion: Combining Persona and Context\n",
        "#         fused_representation = attended_context + weighted_persona\n",
        "#         return self.norm(fused_representation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PersonaAdaptiveAttention(nn.Module):\n",
        "    def __init__(self, embed_size, num_heads=4):\n",
        "        super(PersonaAdaptiveAttention, self).__init__()\n",
        "\n",
        "        # Cross-attention layers\n",
        "        self.context_cross_attn = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads)\n",
        "        self.persona_cross_attn = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads)\n",
        "\n",
        "        # Weight computation for persona importance\n",
        "        self.weighting = nn.Linear(embed_size, 1)\n",
        "        \n",
        "        # Normalization and residual connections\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, persona_embeds, context_embeds, decoder_hidden_states):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            - persona_embeds: Encoded persona representation (seq_len, batch, embed_size)\n",
        "            - context_embeds: Encoded context representation (seq_len, batch, embed_size)\n",
        "            - decoder_hidden_states: Hidden states from decoder (seq_len, batch, embed_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # Compute cross-attention between decoder and persona/context\n",
        "        attended_context, _ = self.context_cross_attn(decoder_hidden_states, context_embeds, context_embeds)\n",
        "        attended_persona, _ = self.persona_cross_attn(decoder_hidden_states, persona_embeds, persona_embeds)\n",
        "\n",
        "        # Compute adaptive weighting for persona importance\n",
        "        weights = torch.sigmoid(self.weighting(attended_persona))  # (seq_len, batch, 1)\n",
        "\n",
        "        # Apply Dynamic Masking Mechanism\n",
        "        seq_len = persona_embeds.shape[0]\n",
        "        persona_length = persona_embeds.shape[1]\n",
        "        context_length = context_embeds.shape[1]\n",
        "\n",
        "        # Compute τ (threshold for masking)\n",
        "        tau = context_length / (context_length + persona_length)\n",
        "\n",
        "        # Create binary masks\n",
        "        persona_mask = (weights > tau).float()  # Keep persona info if weight > τ\n",
        "        context_mask = (1 - weights > tau).float()  # Keep context info if weight < 1 - τ\n",
        "\n",
        "        # Apply masks\n",
        "        masked_persona = persona_mask * attended_persona\n",
        "        masked_context = context_mask * attended_context\n",
        "\n",
        "        # Combine masked representations\n",
        "        fused_representation = masked_persona + masked_context\n",
        "\n",
        "        return self.norm(fused_representation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TC_J-b7GrMTC"
      },
      "outputs": [],
      "source": [
        "# class DialogueDecoder(nn.Module):\n",
        "#     def __init__(self, model_name=\"gpt2\", embed_size = EMBEDDING_SIZE):\n",
        "#         super(DialogueDecoder, self).__init__()\n",
        "#         self.gpt2 = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "#     def forward(self, input_embeds, response_tokens):\n",
        "#         outputs = self.gpt2(inputs_embeds=input_embeds, labels=response_tokens)\n",
        "#         return outputs.loss, outputs.logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "class DialogueDecoder(nn.Module):\n",
        "    def __init__(self, model_name=\"gpt2\", embed_size=768):\n",
        "        super(DialogueDecoder, self).__init__()\n",
        "        self.gpt2 = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "        \n",
        "        # Linear layer to match input dimensions\n",
        "        self.fusion_projection = nn.Linear(embed_size, self.gpt2.config.n_embd)\n",
        "\n",
        "    def forward(self, fused_representation, response_tokens):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            - fused_representation: Output from Persona-Adaptive Attention (seq_len, batch, embed_size)\n",
        "            - response_tokens: Tokenized response input (batch, seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        # Project fused_representation to match GPT-2 hidden size\n",
        "        fused_representation = self.fusion_projection(fused_representation)\n",
        "\n",
        "        # Prepend fused persona-context embeddings as a prompt\n",
        "        inputs_embeds = self.gpt2.transformer.wte(response_tokens)  # GPT-2 embeddings\n",
        "        inputs_embeds = torch.cat([fused_representation, inputs_embeds], dim=1)  # Prepend PAA output\n",
        "\n",
        "        # Pass through GPT-2 decoder\n",
        "        outputs = self.gpt2(inputs_embeds=inputs_embeds, labels=response_tokens)\n",
        "\n",
        "        return outputs.loss, outputs.logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GBlxmCalrSxu"
      },
      "outputs": [],
      "source": [
        "# class PersonaAdaptiveChatbot(nn.Module):\n",
        "#     def __init__(self, embed_size = EMBEDDING_SIZE, model_name=\"gpt2\"):\n",
        "#         super(PersonaAdaptiveChatbot, self).__init__()\n",
        "\n",
        "#         self.persona_encoder = PersonaEncoder(embed_size)\n",
        "#         self.context_encoder = ContextEncoder(embed_size)\n",
        "#         self.paa = PersonaAdaptiveAttention(embed_size)\n",
        "#         self.decoder = DialogueDecoder(model_name, embed_size)\n",
        "\n",
        "#         self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "#     def forward(self, persona_tokens, context_tokens, response_tokens):\n",
        "#         # Token Embeddings\n",
        "#         persona_embeds = self.decoder.gpt2.transformer.wte(persona_tokens)\n",
        "#         context_embeds = self.decoder.gpt2.transformer.wte(context_tokens)\n",
        "\n",
        "#         # Encoders\n",
        "#         encoded_persona = self.persona_encoder(persona_embeds)\n",
        "#         encoded_context = self.context_encoder(context_embeds)\n",
        "\n",
        "#         # Persona-Adaptive Attention\n",
        "#         fused_representation = self.paa(encoded_persona, encoded_context)\n",
        "\n",
        "#         # Use PAA Output for GPT-2 Decoder\n",
        "#         response_embeds = self.decoder.gpt2.transformer.wte(response_tokens)\n",
        "#         response_embeds = response_embeds + fused_representation  # Inject PAA info\n",
        "\n",
        "#         return self.decoder(response_embeds, response_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "class PersonaAdaptiveChatbot(nn.Module):\n",
        "    def __init__(self, embed_size=768, model_name=\"gpt2\"):\n",
        "        super(PersonaAdaptiveChatbot, self).__init__()\n",
        "\n",
        "        # Encoders\n",
        "        self.persona_encoder = PersonaEncoder(embed_size)\n",
        "        self.context_encoder = ContextEncoder(embed_size)\n",
        "\n",
        "        # Persona-Adaptive Attention\n",
        "        self.paa = PersonaAdaptiveAttention(embed_size)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = DialogueDecoder(model_name, embed_size)\n",
        "\n",
        "        # Tokenizer for text processing\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, persona_tokens, context_tokens, response_tokens):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            - persona_tokens: Tokenized persona input (batch, seq_len)\n",
        "            - context_tokens: Tokenized context input (batch, seq_len)\n",
        "            - response_tokens: Tokenized response input (batch, seq_len)\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert token IDs to embeddings using GPT-2 word embeddings\n",
        "        persona_embeds = self.decoder.gpt2.transformer.wte(persona_tokens)\n",
        "        context_embeds = self.decoder.gpt2.transformer.wte(context_tokens)\n",
        "\n",
        "        # Encode persona and context\n",
        "        encoded_persona = self.persona_encoder(persona_embeds.permute(1, 0, 2))  # (seq_len, batch, embed)\n",
        "        encoded_context = self.context_encoder(context_embeds.permute(1, 0, 2))  # (seq_len, batch, embed)\n",
        "\n",
        "        # Persona-Adaptive Attention (PAA) to fuse persona and context\n",
        "        fused_representation = self.paa(encoded_persona, encoded_context, decoder_hidden_states=None)\n",
        "\n",
        "        # Use PAA output in GPT-2 Decoder\n",
        "        return self.decoder(fused_representation, response_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "61a5014958f5495798561c4697e9de70",
            "e284e993441d40d3a48a0cf97c01510d",
            "7ee228e1d02147c59bb63cdfae3092f7",
            "f60cb19894c048cc9ce162d8730db1c3",
            "2504ba6203b444b891a535a6cf0fd25d",
            "d240c853bf384ff4a310ecba6278930d",
            "26b24be79d0b49409e81f23280646bd4",
            "f177eb752d054b6688fb709914e538f4",
            "df71db5b4c32417f8617926089cc4114",
            "fb93f38e64ca4fb6b05095a3438d0e16",
            "451f53de6bd045f68b36cfb1c583e0c7",
            "9998d797c7064ee3a8524a26ee056d18",
            "7c6fac1ff8a04350bc7211164490d36b",
            "985ed36d66f242339f3ce1fe12701b66",
            "0f530b734f71469884a487565f9e2100",
            "5105b10e2c6447ab80bb2e1bce325608",
            "144f0ece6f464543ae326f2db93386a1",
            "16c9678911f04df7b20cb8a5a981d322",
            "83e3f1ed8a524c32a00323e0164ac169",
            "dfb5e683cd7d467e8684a84adf4f5fde",
            "98a3a12c489543bc8cc5fe48473c798d",
            "87abe89d50b4449f83d368f410a2daa4",
            "c5e76bf335a540198b73123da74c4665",
            "05caaa1d51004e5583900e6a525d6ab3",
            "c16b3ed2f7e64cfbbf6410aef2c9a3c3",
            "3d19a64b77654f3a81e05ed580b904ce",
            "fc6f0fd8e0bb429a957139a91f28ec75",
            "f83c2d21cbc840918eaf0d708a051f3b",
            "df6b12132d524314ae25ea6a19728f65",
            "1aa04721fc73481393a27ae044c626d5",
            "46a47ba0400c44dea7c600362b510be7",
            "f72e254c4222475f9ef1f5bbaa109a07",
            "b9ab6aff2a834b18bd229d8e1208813b",
            "6fbfa6eca6a6475cbcc6b391f79fb241",
            "01d2b8efbae747a0a62ed54416c2b38a",
            "de8975c2a5de4e9b8267e60d29e8297b",
            "89b520b082a64425974f956a9721383d",
            "fb8a3be60f5742afad835b0d44940d22",
            "c3fb1c0ec9ec4609b386dd70f7b3c064",
            "ecb7cc3deb644661aa617a336bc632fc",
            "35ceaa2ead59452db19d95265a8637cc",
            "d54267854af54cd785997a1fdf9dc86b",
            "81064f31891d42dfaadc0457dc594c23",
            "a4528eafaa3c458c82e539c05b15d30a",
            "59cbd313483444479c598204be31a752",
            "fbf6f7e2599d42bb815fbe71d0133d84",
            "ed2370e2e6a0421a81dcbcedbf69430f",
            "dbedf0d53b27484b82e01e9dd75ce02d",
            "5aefa2e4b6084b05bc7d048c4f6e90c3",
            "4c4e61f6ca21480d8ef91fa9f104d636",
            "5a60f8910b9a46fa86a1f843d399a3d3",
            "b926509cd79d44139090743b8777c531",
            "9266c5ebe1374d2f93a9ea2187c5da09",
            "7020ae7d50e545f88733bc4daa1aab2f",
            "05b1ca143c8c4563ba5033357aa9ddd5"
          ]
        },
        "id": "g7SAwPmysGKE",
        "outputId": "fa212732-7395-4c68-959e-884d3eae4d8a"
      },
      "outputs": [],
      "source": [
        "# # Load GPT-2 tokenizer\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir=\"downloaded_LM\")  # GPT-2 tokenizer with caching\n",
        "# tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a padding token\n",
        "\n",
        "# # Tokenization function\n",
        "# def tokenize_texts(persona, context, response, max_length = MAX_LENGTH_TOKEN):\n",
        "#     persona_tokens = tokenizer(persona, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "#     context_tokens = tokenizer(context, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "#     response_tokens = tokenizer(response, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "#     return persona_tokens.squeeze(0), context_tokens.squeeze(0), response_tokens.squeeze(0)\n",
        "\n",
        "# # Apply tokenization to the entire dataset\n",
        "# df[\"tokenized\"] = df.apply(lambda row: tokenize_texts(row[\"personas\"], row[\"context\"], row[\"act_response\"]), axis=1)\n",
        "\n",
        "# # Extract tokenized tensors\n",
        "# persona_tensors = torch.stack([x[0] for x in df[\"tokenized\"]])\n",
        "# context_tensors = torch.stack([x[1] for x in df[\"tokenized\"]])\n",
        "# response_tensors = torch.stack([x[2] for x in df[\"tokenized\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir=\"downloaded_LM\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a padding token\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_texts(persona, context, response, max_length=MAX_LENGTH_TOKEN):\n",
        "    persona_tokens = tokenizer(persona, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    context_tokens = tokenizer(context, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    response_tokens = tokenizer(response, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # Ensure correct shape (batch, seq_len)\n",
        "    persona_tokens = persona_tokens.squeeze(0)\n",
        "    context_tokens = context_tokens.squeeze(0)\n",
        "    response_tokens = response_tokens.squeeze(0)\n",
        "\n",
        "    return persona_tokens, context_tokens, response_tokens\n",
        "\n",
        "# Apply tokenization to the dataset\n",
        "df[\"tokenized\"] = df.apply(lambda row: tokenize_texts(row[\"personas\"], row[\"context\"], row[\"act_response\"]), axis=1)\n",
        "\n",
        "# Extract tokenized tensors\n",
        "persona_tensors = torch.stack([x[0] for x in df[\"tokenized\"]])\n",
        "context_tensors = torch.stack([x[1] for x in df[\"tokenized\"]])\n",
        "response_tensors = torch.stack([x[2] for x in df[\"tokenized\"]])\n",
        "\n",
        "# Ensure batch-first format\n",
        "persona_tensors = persona_tensors.permute(1, 0)  # Shape (batch, seq_len)\n",
        "context_tensors = context_tensors.permute(1, 0)  # Shape (batch, seq_len)\n",
        "response_tensors = response_tensors.permute(1, 0)  # Shape (batch, seq_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vjOZm3bnsJro"
      },
      "outputs": [],
      "source": [
        "class FoCusDataset(Dataset):\n",
        "    def __init__(self, persona_tensors, context_tensors, response_tensors):\n",
        "        self.persona_tensors = persona_tensors\n",
        "        self.context_tensors = context_tensors\n",
        "        self.response_tensors = response_tensors\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.persona_tensors)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"personas\": self.persona_tensors[idx],\n",
        "            \"context\": self.context_tensors[idx],\n",
        "            \"response\": self.response_tensors[idx],\n",
        "        }\n",
        "\n",
        "# Create dataset\n",
        "dataset = FoCusDataset(persona_tensors, context_tensors, response_tensors)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e04f4b4396f04b6e92dabb701b49dc0e",
            "397881bf12184e358b8945d156895151",
            "2126be9659bc429e937b412d086df743",
            "d2a2448886e24eff8ebec2ebdb863517",
            "0846ee51bb66438a8dfc2e1f8110034f",
            "f75d18980afc47b6865ab40755295d1a",
            "3819120ab6f84f2c8408bff2f9284ff4",
            "721b61f6a28b43f88b6aecab3205c9d0",
            "a4fc7f0b8956432ba4824a0cc76e0845",
            "eecfc865759847b098f341a894a011c7",
            "b4e3e278ef0f43e7b9bcab1889577acb",
            "812cfa32fa0b4297bfe0cd50c040cf73",
            "e3d97907c1684558bfe646c212c5f7a3",
            "9aacc043da1240a6aec3321399f611b3",
            "ffbf527fd0d2499e906a82e7e2982a5f",
            "0a5f99a03d8241d3b08f6aff3f72dbfd",
            "91484284b9a94000be56de1e93f621b5",
            "a6049ab5dc2e43fcb7190ead5ca91c71",
            "22e84ddb50c74369ab21ee9f8137f8cc",
            "02c17865c2e2478e9f0c596420e989d7",
            "abc11e42caff4f4791e3e07504a36a88",
            "b5fac9b77a1a4e2094f7fdbaeeea0cc7"
          ]
        },
        "id": "LmBiLH4EtOXX",
        "outputId": "e822e88a-57e1-4709-a1b1-77d1b4db0bae"
      },
      "outputs": [],
      "source": [
        "# # Define model\n",
        "# model = PersonaAdaptiveChatbot()\n",
        "\n",
        "# # Define optimizer\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "# # Define loss function (GPT-2 uses CrossEntropyLoss)\n",
        "# criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_SAVE_DIR = f\"trained_model/{DATASET}\"\n",
        "\n",
        "\n",
        "# Define model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PersonaAdaptiveChatbot().to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nlwgw8Vrj3G",
        "outputId": "cd88e6b6-9053-4feb-b2db-cd81bee22c5f"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "# import os\n",
        "\n",
        "# # Set device for training\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# def train(model, dataloader, optimizer, num_epochs = EPOCS):\n",
        "#     model.to(device)  # Move model to GPU\n",
        "#     model.train()\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         total_loss = 0\n",
        "#         progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
        "\n",
        "#         for batch in progress_bar:\n",
        "#             # Move batch tensors to GPU\n",
        "#             persona_tokens = batch[\"personas\"].to(device)\n",
        "#             context_tokens = batch[\"context\"].to(device)\n",
        "#             response_tokens = batch[\"response\"].to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             loss, logits = model(persona_tokens, context_tokens, response_tokens)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             total_loss += loss.item()\n",
        "\n",
        "#             # Update tqdm progress bar with current loss\n",
        "#             progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "#     # Save the model after each epoch\n",
        "#     model_save_path = os.path.join(MODEL_SAVE_DIR, f\"model_epoch_{EPOCS}.pth\")\n",
        "#     torch.save(model.state_dict(), model_save_path)\n",
        "#     print(f\"Model saved at: {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Set device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(model, dataloader, optimizer, num_epochs=EPOCS):\n",
        "    model.to(device)  # Move model to GPU\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            # Move batch tensors to GPU\n",
        "            persona_tokens = batch[\"personas\"].to(device)\n",
        "            context_tokens = batch[\"context\"].to(device)\n",
        "            response_tokens = batch[\"response\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            loss, logits = model(persona_tokens, context_tokens, response_tokens)\n",
        "            \n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update tqdm progress bar with current loss\n",
        "            progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "        # Save the model after each epoch\n",
        "        model_save_path = os.path.join(MODEL_SAVE_DIR, f\"model_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        print(f\"Model saved at: {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/100:   0%|          | 0/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 37.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 29.46 GiB is free. Process 544030 has 11.51 GiB memory in use. Including non-PyTorch memory, this process has 6.32 GiB memory in use. Of the allocated memory 4.63 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with CSV data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m loss, logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersona_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[9], line 33\u001b[0m, in \u001b[0;36mPersonaAdaptiveChatbot.forward\u001b[0;34m(self, persona_tokens, context_tokens, response_tokens)\u001b[0m\n\u001b[1;32m     30\u001b[0m context_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mgpt2\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(context_tokens)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Encode persona and context\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m encoded_persona \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersona_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersona_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (seq_len, batch, embed)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m encoded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_encoder(context_embeds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# (seq_len, batch, embed)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Persona-Adaptive Attention (PAA) to fuse persona and context\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mPersonaEncoder.forward\u001b[0;34m(self, persona_embeds)\u001b[0m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m persona_embeds  \u001b[38;5;66;03m# Shape: (seq_len, batch_size, embed_size)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Self-attention layer\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     attn_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attn_output))  \u001b[38;5;66;03m# Residual connection + LayerNorm\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Feed-forward network\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1373\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1348\u001b[0m         query,\n\u001b[1;32m   1349\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1373\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m~/Desktop/PAA_Implementation/.venv/lib/python3.10/site-packages/torch/nn/functional.py:6373\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6369\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbaddbmm(\n\u001b[1;32m   6370\u001b[0m         attn_mask, q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   6371\u001b[0m     )\n\u001b[1;32m   6372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6373\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6374\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   6375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 37.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 29.46 GiB is free. Process 544030 has 11.51 GiB memory in use. Including non-PyTorch memory, this process has 6.32 GiB memory in use. Of the allocated memory 4.63 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Train the model with CSV data\n",
        "train(model, train_loader, optimizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Response Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET = \"FoCus\"\n",
        "MODEL_SAVE_DIR = f\"trained_model/{DATASET}\"\n",
        "EPOCS = 100\n",
        "MAX_LENGTH_TOKEN = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PersonaAdaptiveChatbot(\n",
              "  (persona_encoder): PersonaEncoder(\n",
              "    (attention): SelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (context_encoder): ContextEncoder(\n",
              "    (attention): SelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (paa): PersonaAdaptiveAttention(\n",
              "    (context_attention): SelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "    )\n",
              "    (persona_attention): SelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "    )\n",
              "    (weighting): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): DialogueDecoder(\n",
              "    (gpt2): GPT2LMHeadModel(\n",
              "      (transformer): GPT2Model(\n",
              "        (wte): Embedding(50257, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): GPT2Attention(\n",
              "              (c_attn): Conv1D(nf=2304, nx=768)\n",
              "              (c_proj): Conv1D(nf=768, nx=768)\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): Conv1D(nf=3072, nx=768)\n",
              "              (c_proj): Conv1D(nf=768, nx=3072)\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = PersonaAdaptiveChatbot()  # Recreate the model architecture\n",
        "model.load_state_dict(torch.load(f\"{MODEL_SAVE_DIR}/model_epoch_{EPOCS}.pth\"))\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HyJBu8H6rptm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Response: user1: What's your favorite movie?\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate_response(model, persona_text, context_text, max_length= MAX_LENGTH_TOKEN):\n",
        "    model.to(device)  # Ensure model is on GPU\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and move to GPU, ensuring padding for alignment\n",
        "    persona_tokens = tokenizer(persona_text, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"].to(device)\n",
        "    context_tokens = tokenizer(context_text, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        persona_embeds = model.decoder.gpt2.transformer.wte(persona_tokens)\n",
        "        context_embeds = model.decoder.gpt2.transformer.wte(context_tokens)\n",
        "\n",
        "        # Determine max sequence length for padding\n",
        "        max_seq_len = max(persona_embeds.shape[1], context_embeds.shape[1])\n",
        "\n",
        "        # Pad tensors to the same length\n",
        "        pad_size_persona = max_seq_len - persona_embeds.shape[1]\n",
        "        pad_size_context = max_seq_len - context_embeds.shape[1]\n",
        "\n",
        "        persona_embeds = torch.nn.functional.pad(persona_embeds, (0, 0, 0, pad_size_persona), \"constant\", 0)\n",
        "        context_embeds = torch.nn.functional.pad(context_embeds, (0, 0, 0, pad_size_context), \"constant\", 0)\n",
        "\n",
        "        # Encode using persona and context encoders\n",
        "        encoded_persona = model.persona_encoder(persona_embeds)\n",
        "        encoded_context = model.context_encoder(context_embeds)\n",
        "\n",
        "        # Apply Persona-Adaptive Attention (PAA)\n",
        "        fused_representation = model.paa(encoded_persona, encoded_context)\n",
        "\n",
        "    # Generate response ensuring input is on GPU\n",
        "    generated = model.decoder.gpt2.generate(input_ids=context_tokens, max_length=max_length).to(device)\n",
        "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# Example\n",
        "persona_text = \"I love sci-fi movies.\"\n",
        "context_text = \"user1: What's your favorite movie?\"\n",
        "response = generate_response(model, persona_text, context_text)\n",
        "print(\"Generated Response:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d2b8efbae747a0a62ed54416c2b38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3fb1c0ec9ec4609b386dd70f7b3c064",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb7cc3deb644661aa617a336bc632fc",
            "value": "tokenizer.json: 100%"
          }
        },
        "02c17865c2e2478e9f0c596420e989d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05b1ca143c8c4563ba5033357aa9ddd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05caaa1d51004e5583900e6a525d6ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83c2d21cbc840918eaf0d708a051f3b",
            "placeholder": "​",
            "style": "IPY_MODEL_df6b12132d524314ae25ea6a19728f65",
            "value": "merges.txt: 100%"
          }
        },
        "0846ee51bb66438a8dfc2e1f8110034f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5f99a03d8241d3b08f6aff3f72dbfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f530b734f71469884a487565f9e2100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a3a12c489543bc8cc5fe48473c798d",
            "placeholder": "​",
            "style": "IPY_MODEL_87abe89d50b4449f83d368f410a2daa4",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 6.27MB/s]"
          }
        },
        "144f0ece6f464543ae326f2db93386a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c9678911f04df7b20cb8a5a981d322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa04721fc73481393a27ae044c626d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2126be9659bc429e937b412d086df743": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_721b61f6a28b43f88b6aecab3205c9d0",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4fc7f0b8956432ba4824a0cc76e0845",
            "value": 548105171
          }
        },
        "22e84ddb50c74369ab21ee9f8137f8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2504ba6203b444b891a535a6cf0fd25d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b24be79d0b49409e81f23280646bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ceaa2ead59452db19d95265a8637cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3819120ab6f84f2c8408bff2f9284ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "397881bf12184e358b8945d156895151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75d18980afc47b6865ab40755295d1a",
            "placeholder": "​",
            "style": "IPY_MODEL_3819120ab6f84f2c8408bff2f9284ff4",
            "value": "model.safetensors: 100%"
          }
        },
        "3d19a64b77654f3a81e05ed580b904ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72e254c4222475f9ef1f5bbaa109a07",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ab6aff2a834b18bd229d8e1208813b",
            "value": " 456k/456k [00:00&lt;00:00, 4.90MB/s]"
          }
        },
        "451f53de6bd045f68b36cfb1c583e0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a47ba0400c44dea7c600362b510be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c4e61f6ca21480d8ef91fa9f104d636": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5105b10e2c6447ab80bb2e1bce325608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cbd313483444479c598204be31a752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbf6f7e2599d42bb815fbe71d0133d84",
              "IPY_MODEL_ed2370e2e6a0421a81dcbcedbf69430f",
              "IPY_MODEL_dbedf0d53b27484b82e01e9dd75ce02d"
            ],
            "layout": "IPY_MODEL_5aefa2e4b6084b05bc7d048c4f6e90c3"
          }
        },
        "5a60f8910b9a46fa86a1f843d399a3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aefa2e4b6084b05bc7d048c4f6e90c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a5014958f5495798561c4697e9de70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e284e993441d40d3a48a0cf97c01510d",
              "IPY_MODEL_7ee228e1d02147c59bb63cdfae3092f7",
              "IPY_MODEL_f60cb19894c048cc9ce162d8730db1c3"
            ],
            "layout": "IPY_MODEL_2504ba6203b444b891a535a6cf0fd25d"
          }
        },
        "6fbfa6eca6a6475cbcc6b391f79fb241": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01d2b8efbae747a0a62ed54416c2b38a",
              "IPY_MODEL_de8975c2a5de4e9b8267e60d29e8297b",
              "IPY_MODEL_89b520b082a64425974f956a9721383d"
            ],
            "layout": "IPY_MODEL_fb8a3be60f5742afad835b0d44940d22"
          }
        },
        "7020ae7d50e545f88733bc4daa1aab2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721b61f6a28b43f88b6aecab3205c9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6fac1ff8a04350bc7211164490d36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144f0ece6f464543ae326f2db93386a1",
            "placeholder": "​",
            "style": "IPY_MODEL_16c9678911f04df7b20cb8a5a981d322",
            "value": "vocab.json: 100%"
          }
        },
        "7ee228e1d02147c59bb63cdfae3092f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f177eb752d054b6688fb709914e538f4",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df71db5b4c32417f8617926089cc4114",
            "value": 26
          }
        },
        "81064f31891d42dfaadc0457dc594c23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812cfa32fa0b4297bfe0cd50c040cf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3d97907c1684558bfe646c212c5f7a3",
              "IPY_MODEL_9aacc043da1240a6aec3321399f611b3",
              "IPY_MODEL_ffbf527fd0d2499e906a82e7e2982a5f"
            ],
            "layout": "IPY_MODEL_0a5f99a03d8241d3b08f6aff3f72dbfd"
          }
        },
        "83e3f1ed8a524c32a00323e0164ac169": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87abe89d50b4449f83d368f410a2daa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b520b082a64425974f956a9721383d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81064f31891d42dfaadc0457dc594c23",
            "placeholder": "​",
            "style": "IPY_MODEL_a4528eafaa3c458c82e539c05b15d30a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "91484284b9a94000be56de1e93f621b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9266c5ebe1374d2f93a9ea2187c5da09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "985ed36d66f242339f3ce1fe12701b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83e3f1ed8a524c32a00323e0164ac169",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfb5e683cd7d467e8684a84adf4f5fde",
            "value": 1042301
          }
        },
        "98a3a12c489543bc8cc5fe48473c798d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9998d797c7064ee3a8524a26ee056d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c6fac1ff8a04350bc7211164490d36b",
              "IPY_MODEL_985ed36d66f242339f3ce1fe12701b66",
              "IPY_MODEL_0f530b734f71469884a487565f9e2100"
            ],
            "layout": "IPY_MODEL_5105b10e2c6447ab80bb2e1bce325608"
          }
        },
        "9aacc043da1240a6aec3321399f611b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e84ddb50c74369ab21ee9f8137f8cc",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02c17865c2e2478e9f0c596420e989d7",
            "value": 124
          }
        },
        "a4528eafaa3c458c82e539c05b15d30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4fc7f0b8956432ba4824a0cc76e0845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6049ab5dc2e43fcb7190ead5ca91c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abc11e42caff4f4791e3e07504a36a88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e3e278ef0f43e7b9bcab1889577acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5fac9b77a1a4e2094f7fdbaeeea0cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b926509cd79d44139090743b8777c531": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ab6aff2a834b18bd229d8e1208813b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c16b3ed2f7e64cfbbf6410aef2c9a3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa04721fc73481393a27ae044c626d5",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46a47ba0400c44dea7c600362b510be7",
            "value": 456318
          }
        },
        "c3fb1c0ec9ec4609b386dd70f7b3c064": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e76bf335a540198b73123da74c4665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05caaa1d51004e5583900e6a525d6ab3",
              "IPY_MODEL_c16b3ed2f7e64cfbbf6410aef2c9a3c3",
              "IPY_MODEL_3d19a64b77654f3a81e05ed580b904ce"
            ],
            "layout": "IPY_MODEL_fc6f0fd8e0bb429a957139a91f28ec75"
          }
        },
        "d240c853bf384ff4a310ecba6278930d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a2448886e24eff8ebec2ebdb863517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecfc865759847b098f341a894a011c7",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e3e278ef0f43e7b9bcab1889577acb",
            "value": " 548M/548M [00:07&lt;00:00, 98.4MB/s]"
          }
        },
        "d54267854af54cd785997a1fdf9dc86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbedf0d53b27484b82e01e9dd75ce02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7020ae7d50e545f88733bc4daa1aab2f",
            "placeholder": "​",
            "style": "IPY_MODEL_05b1ca143c8c4563ba5033357aa9ddd5",
            "value": " 665/665 [00:00&lt;00:00, 23.7kB/s]"
          }
        },
        "de8975c2a5de4e9b8267e60d29e8297b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ceaa2ead59452db19d95265a8637cc",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d54267854af54cd785997a1fdf9dc86b",
            "value": 1355256
          }
        },
        "df6b12132d524314ae25ea6a19728f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df71db5b4c32417f8617926089cc4114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfb5e683cd7d467e8684a84adf4f5fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e04f4b4396f04b6e92dabb701b49dc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_397881bf12184e358b8945d156895151",
              "IPY_MODEL_2126be9659bc429e937b412d086df743",
              "IPY_MODEL_d2a2448886e24eff8ebec2ebdb863517"
            ],
            "layout": "IPY_MODEL_0846ee51bb66438a8dfc2e1f8110034f"
          }
        },
        "e284e993441d40d3a48a0cf97c01510d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d240c853bf384ff4a310ecba6278930d",
            "placeholder": "​",
            "style": "IPY_MODEL_26b24be79d0b49409e81f23280646bd4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e3d97907c1684558bfe646c212c5f7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91484284b9a94000be56de1e93f621b5",
            "placeholder": "​",
            "style": "IPY_MODEL_a6049ab5dc2e43fcb7190ead5ca91c71",
            "value": "generation_config.json: 100%"
          }
        },
        "ecb7cc3deb644661aa617a336bc632fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2370e2e6a0421a81dcbcedbf69430f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b926509cd79d44139090743b8777c531",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9266c5ebe1374d2f93a9ea2187c5da09",
            "value": 665
          }
        },
        "eecfc865759847b098f341a894a011c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f177eb752d054b6688fb709914e538f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60cb19894c048cc9ce162d8730db1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb93f38e64ca4fb6b05095a3438d0e16",
            "placeholder": "​",
            "style": "IPY_MODEL_451f53de6bd045f68b36cfb1c583e0c7",
            "value": " 26.0/26.0 [00:00&lt;00:00, 377B/s]"
          }
        },
        "f72e254c4222475f9ef1f5bbaa109a07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75d18980afc47b6865ab40755295d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83c2d21cbc840918eaf0d708a051f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb8a3be60f5742afad835b0d44940d22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb93f38e64ca4fb6b05095a3438d0e16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf6f7e2599d42bb815fbe71d0133d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4e61f6ca21480d8ef91fa9f104d636",
            "placeholder": "​",
            "style": "IPY_MODEL_5a60f8910b9a46fa86a1f843d399a3d3",
            "value": "config.json: 100%"
          }
        },
        "fc6f0fd8e0bb429a957139a91f28ec75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbf527fd0d2499e906a82e7e2982a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abc11e42caff4f4791e3e07504a36a88",
            "placeholder": "​",
            "style": "IPY_MODEL_b5fac9b77a1a4e2094f7fdbaeeea0cc7",
            "value": " 124/124 [00:00&lt;00:00, 1.76kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
